---
title: "Why the Otter.ai lawsuit matters: consent should be your choice, not your tool's liability"
description: "When meeting bots join your calls, who's liable for the recording? The Brewer v. Otter.ai case raises questions every team using AI meeting tools should ask."
author: "Dima"
publishedDate: 2026-02-02
image: "/blog-otter-lawsuit-consent-liability.png"
imageAlt: "A video call interface with a bot icon joining uninvited, showing a warning symbol and broken chain link representing liability"
tags: ["meeting-notes", "privacy", "legal", "consent", "local-ai"]
---

In August 2025, Justin Brewer sued Otter.ai â€” not because he used it, but because someone else did. Their bot joined his calls, recorded him, and sent his voice to company servers. Without consent. Without warning.

The lawsuit raises a question every team using AI meeting tools should ask: when your note-taker records someone, who's liable?

> ðŸ“– Previously: [Please stop inviting meeting bots](/blog/please-stop-inviting-meeting-bots) â€” including the story of how Fireflies founders manually joined calls pretending to be a bot named "Fred".

## The Brewer v. Otter.ai case

- Plaintiff was NOT an Otter user â€” just a meeting participant
- OtterPilot bot joined Zoom/Meet/Teams calls automatically
- By default, did NOT ask other attendees for permission ([NPR](https://www.npr.org/2025/08/15/g-s1-83087/otter-ai-transcription-class-action-lawsuit))
- Audio transmitted to Otter servers = potential wiretapping claim

The lawsuit targets Otter the company â€” not the user who invited the bot. Because when a third-party service actively joins calls and collects data, it becomes a party to the recording.

## Bot = intermediary = liability

Meeting bots create a legal chain: User â†’ Bot â†’ Company servers. The company becomes an active participant in data collection, not just a tool provider.

With bots, the breach is instant and total: bot joins â†’ audio streams to servers. In a 50-person call where the bot joins mid-meeting, you can't even pinpoint when the leak happened.

Local-first tools contain the blast radius. Recording requires authorization from an actual invited participant. Even if something goes wrong, data stays on one machine â€” the breach window is limited to a single computer, not a company's entire server infrastructure.

## The alternative: tools, not intermediaries

Local-first meeting tools like Summit take a different approach:

- No bot joins your call â€” no third party in the recording chain
- Audio stays on your device â€” no transmission to company servers
- Explicit disclaimer: user is responsible for obtaining consent
- Warning before recording: reminds user about consent requirements

The tool is just a tool. Responsibility stays with the human making the decision.

## Questions for your current tool

- Does it add a third party to your call?
- Does it transmit audio to external servers?
- Does it obtain consent from ALL participants, or just the host?
- What's their liability model if something goes wrong?

## Bottom line

The Otter lawsuit isn't just about one company â€” it's about the consent model of bot-based meeting tools. When your tool becomes a party to recording, so does your company.

Consent should be your choice and your responsibility â€” not a liability you share with your software vendor.
